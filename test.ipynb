{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":529,"status":"ok","timestamp":1704736375423,"user":{"displayName":"Bilal Abbasi","userId":"12906580337326855029"},"user_tz":-300},"id":"87f27eac","outputId":"b44cf121-ca40-458c-dfd6-c49f226a856c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nCopyright (c) 2019-present NAVER Corp.\\nMIT License\\n'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","Copyright (c) 2019-present NAVER Corp.\n","MIT License\n","\"\"\"\n","\n","# !pip install opencv  # ! used for command line commands in notebooks"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1704736375926,"user":{"displayName":"Bilal Abbasi","userId":"12906580337326855029"},"user_tz":-300},"id":"d7889e97"},"outputs":[],"source":["1# -*- coding: utf-8 -*-\n","import sys\n","import os\n","import time\n","import argparse"]},{"cell_type":"markdown","metadata":{"id":"5b145d39"},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8125,"status":"ok","timestamp":1704736384037,"user":{"displayName":"Bilal Abbasi","userId":"12906580337326855029"},"user_tz":-300},"id":"99d002a6"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from torch.autograd import Variable"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":158,"status":"ok","timestamp":1704736384108,"user":{"displayName":"Bilal Abbasi","userId":"12906580337326855029"},"user_tz":-300},"id":"98cdac29"},"outputs":[],"source":["from PIL import Image"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1704736384109,"user":{"displayName":"Bilal Abbasi","userId":"12906580337326855029"},"user_tz":-300},"id":"ScCGyKk6ZTSZ"},"outputs":[],"source":["from google.colab import drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hOWdGoJUaE73"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WjBoXouDbCDo"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/CRAFT FYP\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/CRAFT FYP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2d04e12c"},"outputs":[],"source":["!pip install scikit-image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d698191e"},"outputs":[],"source":["import cv2\n","\n","from skimage import io\n","import numpy as np\n","import craft_utils\n","import imgproc\n","import file_utils\n","\n","import json\n","import zipfile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"be47839f"},"outputs":[],"source":["print(cudnn.is_available())\n","print (torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXo9rVmkbhku"},"outputs":[],"source":["!pip uninstall craft\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d05b4acd"},"outputs":[],"source":["from craft import CRAFT\n","#!ls\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"581d81f4"},"outputs":[],"source":["from collections import OrderedDict\n","def copyStateDict(state_dict):\n","    if list(state_dict.keys())[0].startswith(\"module\"):\n","        start_idx = 1\n","    else:\n","        start_idx = 0\n","    new_state_dict = OrderedDict()\n","    for k, v in state_dict.items():\n","        name = \".\".join(k.split(\".\")[start_idx:])\n","        new_state_dict[name] = v\n","    return new_state_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f828c0a7"},"outputs":[],"source":["def str2bool(v):\n","    return v.lower() in (\"yes\", \"y\", \"true\", \"t\", \"1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"582f1332"},"outputs":[],"source":["parser = argparse.ArgumentParser(description='CRAFT Text Detection')\n","parser.add_argument('--trained_model', default='weights/craft_mlt_25k.pth', type=str, help='pretrained model')\n","parser.add_argument('--text_threshold', default=0.7, type=float, help='text confidence threshold') #0.7\n","parser.add_argument('--low_text', default=0.4, type=float, help='text low-bound score')\n","parser.add_argument('--link_threshold', default=0.2, type=float, help='link confidence threshold') #0.2\n","parser.add_argument('--cuda', default=True, type=str2bool, help='Use cuda for inference')\n","parser.add_argument('--canvas_size', default=1280, type=int, help='image size for inference')\n","parser.add_argument('--mag_ratio', default=2.0, type=float, help='image magnification ratio') # 1.5\n","parser.add_argument('--poly', default=False, action='store_true', help='enable polygon type')\n","parser.add_argument('--show_time', default=False, action='store_true', help='show processing time')\n","parser.add_argument('--test_folder', default='Data', type=str, help='folder path to input images')\n","parser.add_argument('--refine', default=False, action='store_true', help='enable link refiner')\n","parser.add_argument('--refiner_model', default='weights/craft_refiner_CTW1500.pth', type=str, help='pretrained refiner model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8e032a6e"},"outputs":[],"source":["args, unknown = parser.parse_known_args()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57d1c6f8"},"outputs":[],"source":["\"\"\" For test images in a folder \"\"\"\n","image_list, _, _ = file_utils.get_files(args.test_folder)\n","print(args.test_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"61db0091"},"outputs":[],"source":["result_folder = './result/'\n","if not os.path.isdir(result_folder):\n","    os.mkdir(result_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3f864d81"},"outputs":[],"source":["def test_net(net, image, text_threshold, link_threshold, low_text, cuda, poly, refine_net=None):\n","    t0 = time.time()\n","\n","    # resize\n","    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, args.canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=args.mag_ratio)\n","    ratio_h = ratio_w = 1 / target_ratio\n","\n","    # preprocessing\n","    x = imgproc.normalizeMeanVariance(img_resized)\n","    x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n","    x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n","    if cuda:\n","        x = x.cuda()\n","\n","    # forward pass\n","    with torch.no_grad():\n","        y, feature = net(x)\n","\n","    # make score and link map\n","    score_text = y[0,:,:,0].cpu().data.numpy()\n","    score_link = y[0,:,:,1].cpu().data.numpy()\n","\n","    # refine link\n","    if refine_net is not None:\n","        with torch.no_grad():\n","            y_refiner = refine_net(y, feature)\n","        score_link = y_refiner[0,:,:,0].cpu().data.numpy()\n","\n","    t0 = time.time() - t0\n","    t1 = time.time()\n","\n","    # Post-processing\n","    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n","\n","    # coordinate adjustment\n","    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n","    polys = craft_utils.adjustResultCoordinates(polys, ratio_w, ratio_h)\n","    for k in range(len(polys)):\n","        if polys[k] is None: polys[k] = boxes[k]\n","\n","    t1 = time.time() - t1\n","\n","    # render results (optional)\n","    render_img = score_text.copy()\n","    render_img = np.hstack((render_img, score_link))\n","    ret_score_text = imgproc.cvt2HeatmapImg(render_img)\n","\n","    if args.show_time : print(\"\\ninfer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n","\n","    return boxes, polys, ret_score_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b54354fe"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7a2dd9f"},"outputs":[],"source":["\n","if __name__ == '__main__':\n","    # load net\n","    net = CRAFT()     # initialize\n","\n","    print('Loading weights from checkpoint (' + args.trained_model + ')')\n","    if args.cuda:\n","        net.load_state_dict(copyStateDict(torch.load(args.trained_model)))\n","    else:\n","        net.load_state_dict(copyStateDict(torch.load(args.trained_model, map_location='cpu')))\n","\n","    if args.cuda:\n","        net = net.cuda()\n","        net = torch.nn.DataParallel(net)\n","        cudnn.benchmark = False\n","\n","    net.eval()\n","\n","    # LinkRefiner\n","    refine_net = None\n","    if args.refine:\n","        from refinenet import RefineNet\n","        refine_net = RefineNet()\n","        print('Loading weights of refiner from checkpoint (' + args.refiner_model + ')')\n","        if args.cuda:\n","            refine_net.load_state_dict(copyStateDict(torch.load(args.refiner_model)))\n","            refine_net = refine_net.cuda()\n","            refine_net = torch.nn.DataParallel(refine_net)\n","        else:\n","            refine_net.load_state_dict(copyStateDict(torch.load(args.refiner_model, map_location='cpu')))\n","\n","        refine_net.eval()\n","        args.poly = True\n","\n","    t = time.time()\n","\n","    # load data\n","    for k, image_path in enumerate(image_list):\n","        print(\"Test image {:d}/{:d}: {:s}\".format(k+1, len(image_list), image_path), end='\\r')\n","        image = imgproc.loadImage(image_path)\n","\n","        bboxes, polys, score_text = test_net(net, image, args.text_threshold, args.link_threshold, args.low_text, args.cuda, args.poly, refine_net)\n","\n","        # save score text\n","        filename, file_ext = os.path.splitext(os.path.basename(image_path))\n","        mask_file = result_folder + \"/res_\" + filename + '_mask.jpg'\n","        cv2.imwrite(mask_file, score_text)\n","\n","        file_utils.saveResult(image_path, image[:,:,::-1], polys, dirname=result_folder)\n","\n","    print(\"elapsed time : {}s\".format(time.time() - t))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LxMBry4X_KZ5"},"outputs":[],"source":["%cd result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MTdLIRV5_MvR"},"outputs":[],"source":["\n","def group_boxes_by_line(boxes, text_threshold):\n","    lines = []\n","    sorted_boxes = sorted(boxes, key=lambda x: (x[1], x[0]))\n","    current_line = [sorted_boxes[0]]\n","    for box in sorted_boxes[1:]:\n","        if box[1] - current_line[-1][1] \u003c text_threshold:\n","            current_line.append(box)\n","        else:\n","            lines.append(current_line)\n","            current_line = [box]\n","    lines.append(current_line)\n","    return lines\n","def read_bounding_boxes_from_file(file_path):\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","        print(lines)\n","        boxes = [list(map(int, line.strip().split(','))) for line in lines]\n","    return boxes\n","\n","# Read word-level bounding boxes from a text file\n","word_boxes = read_bounding_boxes_from_file('res_Multiple_Qs.txt')\n","\n","# Group the word-level bounding boxes into line-level bounding boxes\n","text_threshold = 10  # Adjust this threshold as needed\n","line_boxes = group_boxes_by_line(word_boxes, 20) # threshold was 50 for the other image\n","\n","# Now `line_boxes` contains bounding boxes grouped by lines\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCMB9amT_sjV"},"outputs":[],"source":["print(line_boxes[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V5hpS3ei_V-a"},"outputs":[],"source":["%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qoqqq3JSAFbY"},"outputs":[],"source":["%cd  Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N6Byvls8_sqS"},"outputs":[],"source":["from PIL import Image\n","\n","# Assuming `image_path` is the path to your input image\n","image_path = 'Multiple_Qs.jpeg'\n","image = Image.open(image_path)\n","\n","# Assuming `line_boxes` contains the line-level bounding boxes in the format (x_min, y_min, x_max, y_max)\n","cropped_images = []\n","result2=[]\n","for i, line in enumerate(line_boxes):\n","  x_min = 9999\n","  y_min= 9999\n","  x_max=-9999\n","  y_max=-9999\n","\n","  for j, box in enumerate(line):\n","        # Assuming each box has 4 points\n","    x_min = min(box[0], box[2], box[4], box[6],x_min)\n","    y_min = min(box[1], box[3], box[5], box[7],y_min)\n","    x_max = max(box[0], box[2], box[4], box[6],x_max)\n","    y_max = max(box[1], box[3], box[5], box[7],y_max)\n","  result2.append((x_min,y_min,x_max,y_min,x_min,y_max,x_max,y_max))\n","\n","# Now `cropped_images` contains PIL image objects of the cropped lines.\n","# You can perform further operations on them.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQrfSrQwEunO"},"outputs":[],"source":["display(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfYhKghzDI_l"},"outputs":[],"source":["img_cropped=[]\n","for i in range(len(result2)): #len(result2)-1\n","  x1, y1, x2, y2, x3, y3, x4, y4 = result2[i]\n","  left = min(x1, x4)\n","  upper = min(y1, y2)\n","  right = max(x2, x3)\n","  lower = max(y3, y4)\n","  img_cropped.append(image.crop((x1, y1, x4, y4)))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D61YvMihkcD5"},"outputs":[],"source":["%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RL7wczXke1w"},"outputs":[],"source":["%cd result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nM7kkbAhUsoS"},"outputs":[],"source":["%cd Crop"]},{"cell_type":"markdown","metadata":{"id":"6eMfvYIkFgbc"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"spdHvLFwEIVf"},"outputs":[],"source":["for i in range (0,len(img_cropped)):\n","  img_cropped[i].save(f'Test_Image{i}.jpg')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNM6YMdyEIZa"},"outputs":[],"source":["!pip install -q transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QP4gE0SZEIe2"},"outputs":[],"source":["from transformers import VisionEncoderDecoderModel\n","model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tRh_Y93nANtm"},"outputs":[],"source":["import re\n","\n","def remove_non_alphabet_characters(input_string):\n","    result_string = re.sub(r'[^a-zA-Z\\s]', '', input_string)\n","    return result_string"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ri9_KMgAL1Lb"},"outputs":[],"source":["  resultant_string =\"\"\n","  from PIL import Image, ImageFilter\n","  from transformers import TrOCRProcessor\n","  for i in range (0,len(img_cropped)):\n","    image=Image.open(f'Test_Image{i}.jpg')\n","    sharpened_img = image.filter(ImageFilter.SHARPEN)\n","    processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n","    # calling the processor is equivalent to calling the feature extractor\n","    pixel_values = processor(sharpened_img, return_tensors=\"pt\").pixel_values\n","\n","    generated_ids = model.generate(pixel_values)\n","    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","    generated_text=remove_non_alphabet_characters(generated_text)\n","    generated_text=generated_text.strip()\n","    if (len(generated_text)\u003e2):\n","      resultant_string+=generated_text.lower()\n","      resultant_string+=\" \"\n","      print(f\"{i}:{generated_text}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":518,"status":"ok","timestamp":1704668101622,"user":{"displayName":"Bilal Abbasi","userId":"12906580337326855029"},"user_tz":-300},"id":"FxH_1DSw_t59","outputId":"9c31886f-36db-4964-8825-5caa65b2416d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[' what were the main causes of the french revolution ', ' the french revolution began in  was fueled by combination of economic social and political factors widespread financial crisis high taries and inequality between the nobility and commoners exacerbated by years of feudalism led to a sense of discontent amongest the masses ']\n","[' how did the industrial revolution impact society in the th century ', ' the industrial revolution spanning from the late th to the mid th century being about profound charges in society  the argararian economics were shifted industrialized economy and led to the urbanization of people ']\n"]}],"source":["split_result = resultant_string.split(\"question\")\n","for i in range (1,len(split_result)):\n","  temp=split_result[i].split(\"answer\")\n","  print(temp)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":560,"status":"ok","timestamp":1704668089540,"user":{"displayName":"Bilal Abbasi","userId":"12906580337326855029"},"user_tz":-300},"id":"oNEJhGuZE86n","outputId":"671aa89e-f640-4d69-a38f-928f68b01b31"},"outputs":[{"name":"stdout","output_type":"stream","text":["['', ' what were the main causes of the french revolution answer the french revolution began in  was fueled by combination of economic social and political factors widespread financial crisis high taries and inequality between the nobility and commoners exacerbated by years of feudalism led to a sense of discontent amongest the masses ', ' how did the industrial revolution impact society in the th century answer the industrial revolution spanning from the late th to the mid th century being about profound charges in society  the argararian economics were shifted industrialized economy and led to the urbanization of people ']\n"]}],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":5}